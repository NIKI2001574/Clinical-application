{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 391,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02557544757033248,
      "grad_norm": 3.1338348388671875,
      "learning_rate": 4.884910485933504e-05,
      "loss": 3.6541,
      "step": 10
    },
    {
      "epoch": 0.05115089514066496,
      "grad_norm": 4.9247212409973145,
      "learning_rate": 4.757033248081842e-05,
      "loss": 3.4803,
      "step": 20
    },
    {
      "epoch": 0.07672634271099744,
      "grad_norm": 7.092491626739502,
      "learning_rate": 4.629156010230179e-05,
      "loss": 3.3078,
      "step": 30
    },
    {
      "epoch": 0.10230179028132992,
      "grad_norm": 5.023067474365234,
      "learning_rate": 4.501278772378517e-05,
      "loss": 3.2122,
      "step": 40
    },
    {
      "epoch": 0.1278772378516624,
      "grad_norm": 5.028077125549316,
      "learning_rate": 4.3734015345268545e-05,
      "loss": 3.1043,
      "step": 50
    },
    {
      "epoch": 0.1534526854219949,
      "grad_norm": 7.15978479385376,
      "learning_rate": 4.245524296675192e-05,
      "loss": 3.1309,
      "step": 60
    },
    {
      "epoch": 0.17902813299232737,
      "grad_norm": 6.77257776260376,
      "learning_rate": 4.11764705882353e-05,
      "loss": 3.1669,
      "step": 70
    },
    {
      "epoch": 0.20460358056265984,
      "grad_norm": 5.343197345733643,
      "learning_rate": 3.989769820971867e-05,
      "loss": 3.0239,
      "step": 80
    },
    {
      "epoch": 0.23017902813299232,
      "grad_norm": 7.193515777587891,
      "learning_rate": 3.861892583120205e-05,
      "loss": 2.8768,
      "step": 90
    },
    {
      "epoch": 0.2557544757033248,
      "grad_norm": 6.1011881828308105,
      "learning_rate": 3.7340153452685426e-05,
      "loss": 3.1253,
      "step": 100
    },
    {
      "epoch": 0.2813299232736573,
      "grad_norm": 6.004255294799805,
      "learning_rate": 3.60613810741688e-05,
      "loss": 3.0482,
      "step": 110
    },
    {
      "epoch": 0.3069053708439898,
      "grad_norm": 5.821318626403809,
      "learning_rate": 3.478260869565218e-05,
      "loss": 3.1398,
      "step": 120
    },
    {
      "epoch": 0.33248081841432225,
      "grad_norm": 6.853426933288574,
      "learning_rate": 3.3503836317135554e-05,
      "loss": 3.0308,
      "step": 130
    },
    {
      "epoch": 0.35805626598465473,
      "grad_norm": 6.656939506530762,
      "learning_rate": 3.222506393861893e-05,
      "loss": 2.7884,
      "step": 140
    },
    {
      "epoch": 0.3836317135549872,
      "grad_norm": 7.402787685394287,
      "learning_rate": 3.0946291560102306e-05,
      "loss": 2.6154,
      "step": 150
    },
    {
      "epoch": 0.4092071611253197,
      "grad_norm": 6.9862260818481445,
      "learning_rate": 2.966751918158568e-05,
      "loss": 2.8489,
      "step": 160
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 7.3878984451293945,
      "learning_rate": 2.8388746803069055e-05,
      "loss": 2.6147,
      "step": 170
    },
    {
      "epoch": 0.46035805626598464,
      "grad_norm": 5.806251049041748,
      "learning_rate": 2.710997442455243e-05,
      "loss": 2.7632,
      "step": 180
    },
    {
      "epoch": 0.4859335038363171,
      "grad_norm": 7.471809387207031,
      "learning_rate": 2.5831202046035807e-05,
      "loss": 2.5164,
      "step": 190
    },
    {
      "epoch": 0.5115089514066496,
      "grad_norm": 8.368844985961914,
      "learning_rate": 2.4552429667519183e-05,
      "loss": 2.6041,
      "step": 200
    },
    {
      "epoch": 0.5370843989769821,
      "grad_norm": 11.242806434631348,
      "learning_rate": 2.327365728900256e-05,
      "loss": 2.6094,
      "step": 210
    },
    {
      "epoch": 0.5626598465473146,
      "grad_norm": 6.398662567138672,
      "learning_rate": 2.1994884910485935e-05,
      "loss": 2.437,
      "step": 220
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 9.395979881286621,
      "learning_rate": 2.071611253196931e-05,
      "loss": 2.6666,
      "step": 230
    },
    {
      "epoch": 0.6138107416879796,
      "grad_norm": 6.270577907562256,
      "learning_rate": 1.9437340153452684e-05,
      "loss": 2.4649,
      "step": 240
    },
    {
      "epoch": 0.639386189258312,
      "grad_norm": 7.3257155418396,
      "learning_rate": 1.815856777493606e-05,
      "loss": 2.486,
      "step": 250
    },
    {
      "epoch": 0.6649616368286445,
      "grad_norm": 10.028624534606934,
      "learning_rate": 1.6879795396419436e-05,
      "loss": 2.3969,
      "step": 260
    },
    {
      "epoch": 0.690537084398977,
      "grad_norm": 6.890646934509277,
      "learning_rate": 1.5601023017902812e-05,
      "loss": 2.1459,
      "step": 270
    },
    {
      "epoch": 0.7161125319693095,
      "grad_norm": 8.627613067626953,
      "learning_rate": 1.432225063938619e-05,
      "loss": 2.4414,
      "step": 280
    },
    {
      "epoch": 0.7416879795396419,
      "grad_norm": 7.14687967300415,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 2.3822,
      "step": 290
    },
    {
      "epoch": 0.7672634271099744,
      "grad_norm": 6.517662048339844,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 2.3511,
      "step": 300
    },
    {
      "epoch": 0.7928388746803069,
      "grad_norm": 7.276721477508545,
      "learning_rate": 1.0485933503836318e-05,
      "loss": 2.6102,
      "step": 310
    },
    {
      "epoch": 0.8184143222506394,
      "grad_norm": 6.994435787200928,
      "learning_rate": 9.207161125319694e-06,
      "loss": 2.4015,
      "step": 320
    },
    {
      "epoch": 0.8439897698209718,
      "grad_norm": 7.7282609939575195,
      "learning_rate": 7.92838874680307e-06,
      "loss": 2.503,
      "step": 330
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 8.104933738708496,
      "learning_rate": 6.649616368286446e-06,
      "loss": 2.4035,
      "step": 340
    },
    {
      "epoch": 0.8951406649616368,
      "grad_norm": 8.637296676635742,
      "learning_rate": 5.370843989769821e-06,
      "loss": 2.1715,
      "step": 350
    },
    {
      "epoch": 0.9207161125319693,
      "grad_norm": 8.83259105682373,
      "learning_rate": 4.092071611253197e-06,
      "loss": 2.1631,
      "step": 360
    },
    {
      "epoch": 0.9462915601023018,
      "grad_norm": 10.774149894714355,
      "learning_rate": 2.813299232736573e-06,
      "loss": 2.4604,
      "step": 370
    },
    {
      "epoch": 0.9718670076726342,
      "grad_norm": 8.810234069824219,
      "learning_rate": 1.534526854219949e-06,
      "loss": 2.5014,
      "step": 380
    },
    {
      "epoch": 0.9974424552429667,
      "grad_norm": 6.854310512542725,
      "learning_rate": 2.5575447570332484e-07,
      "loss": 2.3087,
      "step": 390
    }
  ],
  "logging_steps": 10,
  "max_steps": 391,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 414108594831360.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
